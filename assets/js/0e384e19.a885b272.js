"use strict";(self.webpackChunkapache_streampark_website=self.webpackChunkapache_streampark_website||[]).push([[3976],{15680:(e,a,t)=>{t.d(a,{xA:()=>c,yg:()=>g});var r=t(96540);function n(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function o(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);a&&(r=r.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,r)}return t}function i(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?o(Object(t),!0).forEach((function(a){n(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function p(e,a){if(null==e)return{};var t,r,n=function(e,a){if(null==e)return{};var t,r,n={},o=Object.keys(e);for(r=0;r<o.length;r++)t=o[r],a.indexOf(t)>=0||(n[t]=e[t]);return n}(e,a);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)t=o[r],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(n[t]=e[t])}return n}var s=r.createContext({}),l=function(e){var a=r.useContext(s),t=a;return e&&(t="function"==typeof e?e(a):i(i({},a),e)),t},c=function(e){var a=l(e.components);return r.createElement(s.Provider,{value:a},e.children)},m="mdxType",u={inlineCode:"code",wrapper:function(e){var a=e.children;return r.createElement(r.Fragment,{},a)}},h=r.forwardRef((function(e,a){var t=e.components,n=e.mdxType,o=e.originalType,s=e.parentName,c=p(e,["components","mdxType","originalType","parentName"]),m=l(t),h=n,g=m["".concat(s,".").concat(h)]||m[h]||u[h]||o;return t?r.createElement(g,i(i({ref:a},c),{},{components:t})):r.createElement(g,i({ref:a},c))}));function g(e,a){var t=arguments,n=a&&a.mdxType;if("string"==typeof e||n){var o=t.length,i=new Array(o);i[0]=h;var p={};for(var s in a)hasOwnProperty.call(a,s)&&(p[s]=a[s]);p.originalType=e,p[m]="string"==typeof e?e:n,i[1]=p;for(var l=2;l<o;l++)i[l]=t[l];return r.createElement.apply(null,i)}return r.createElement.apply(null,t)}h.displayName="MDXCreateElement"},95436:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>s,contentTitle:()=>i,default:()=>u,frontMatter:()=>o,metadata:()=>p,toc:()=>l});var r=t(58168),n=(t(96540),t(15680));const o={id:"intro",title:"What is Apache StreamPark\u2122",sidebar_position:1},i="Apache StreamPark\u2122",p={unversionedId:"intro",id:"intro",title:"What is Apache StreamPark\u2122",description:"Make stream processing easier!",source:"@site/docs/intro.md",sourceDirName:".",slug:"/intro",permalink:"/docs/intro",draft:!1,editUrl:"https://github.com/apache/incubator-streampark-website/edit/dev/docs/intro.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{id:"intro",title:"What is Apache StreamPark\u2122",sidebar_position:1},sidebar:"tutorialSidebar",next:{title:"Platform Deployment",permalink:"/docs/user-guide/deployment"}},s={},l=[{value:"\ud83d\ude80 What is Apache StreamPark\u2122",id:"-what-is-apache-streampark",level:2},{value:"Why Apache StreamPark\u2122?",id:"why-apache-streampark",level:2},{value:"\ud83c\udf89 Features",id:"-features",level:2},{value:"\ud83c\udff3\u200d\ud83c\udf08 Architecture of Apache StreamPark\u2122",id:"-architecture-of-apache-streampark",level:2},{value:"1\ufe0f\u20e3 streampark-core",id:"1\ufe0f\u20e3-streampark-core",level:3},{value:"2\ufe0f\u20e3 streampark-console",id:"2\ufe0f\u20e3-streampark-console",level:3}],c={toc:l},m="wrapper";function u(e){let{components:a,...o}=e;return(0,n.yg)(m,(0,r.A)({},c,o,{components:a,mdxType:"MDXLayout"}),(0,n.yg)("h1",{id:"apache-streampark"},"Apache StreamPark\u2122"),(0,n.yg)("p",null,"Make stream processing easier!"),(0,n.yg)("h2",{id:"-what-is-apache-streampark"},"\ud83d\ude80 What is Apache StreamPark\u2122"),(0,n.yg)("p",null,"Apache StreamPark is an easy-to-use stream processing application development framework and one-stop stream processing operation platform. Aimed to make it easy to build and manage streaming applications, StreamPark provides scaffolding for writing streaming process logic with Apache Flink and Apache Spark."),(0,n.yg)("p",null,"StreamPark also provides a professional task management module including task development, scheduling, interactive queries, deployment, operations, and maintenance."),(0,n.yg)("h2",{id:"why-apache-streampark"},"Why Apache StreamPark\u2122?"),(0,n.yg)("p",null,"Apache Flink and Apache Spark are widely used as the next generation of big data streaming computing engines. Based on a foundation of excellent experiences combined with best practices, we extracted the task deployment and runtime parameters into the configuration files. In this way, an easy-to-use ",(0,n.yg)("inlineCode",{parentName:"p"},"RuntimeContext")," with out-of-the-box connectors can bring an easier and more efficient task development experience. It reduces the learning cost and development barriers, so developers can focus on the business logic."),(0,n.yg)("p",null,"On the other hand, It can be challenge for enterprises to use Apache Flink & Apache Spark if there is no professional management platform for Flink & Spark tasks during the deployment phase. StreamPark provides such a professional task management platform as described above."),(0,n.yg)("h2",{id:"-features"},"\ud83c\udf89 Features"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Apache Flink & Apache Spark application development scaffold"),(0,n.yg)("li",{parentName:"ul"},"Supports multiple versions of Apache Flink & Apache Spark"),(0,n.yg)("li",{parentName:"ul"},"Wide range of out-of-the-box connectors"),(0,n.yg)("li",{parentName:"ul"},"One-stop stream processing operation platform"),(0,n.yg)("li",{parentName:"ul"},"Supports catalog, OLAP, streaming warehouse, etc.")),(0,n.yg)("h2",{id:"-architecture-of-apache-streampark"},"\ud83c\udff3\u200d\ud83c\udf08 Architecture of Apache StreamPark\u2122"),(0,n.yg)("p",null,"The overall architecture of Apache StreamPark is shown in the following figure. Apache StreamPark has two parts, ",(0,n.yg)("inlineCode",{parentName:"p"},"streampark-core")," and ",(0,n.yg)("inlineCode",{parentName:"p"},"streampark-console"),"."),(0,n.yg)("p",null,(0,n.yg)("img",{alt:"StreamPark Archite",src:t(60941).A,width:"2734",height:"1311"})),(0,n.yg)("h3",{id:"1\ufe0f\u20e3-streampark-core"},"1\ufe0f\u20e3 streampark-core"),(0,n.yg)("p",null,(0,n.yg)("inlineCode",{parentName:"p"},"streampark-core")," is a framework used during development. It supports coding development, regulates configuration files, and follows the 'convention over configuration' principle."),(0,n.yg)("p",null,(0,n.yg)("inlineCode",{parentName:"p"},"streampark-core")," provides development-time Runtime Content and a series of out-of-the-box Connectors. Cumbersome operations are simplified by extending DataStream-related methods and integrating DataStream and the Flink SQL API. This improves development efficiency and developer experience, because users can focus on the business logic."),(0,n.yg)("h3",{id:"2\ufe0f\u20e3-streampark-console"},"2\ufe0f\u20e3 streampark-console"),(0,n.yg)("p",null,(0,n.yg)("inlineCode",{parentName:"p"},"streampark-console")," is a comprehensive real-time Low Code data platform that can manage Flink tasks more convenient.\nIt integrates the experience of many best practices and integrates many functions such as project compilation, release,\nparameter configuration, startup, savepoint, flame graph, Flink SQL, monitoring, etc., which greatly simplifies the daily operation of Flink tasks and maintenance. The ultimate goal is to create a one-stop big data platform, which can provide a solution that integrates flow and batch, and integrates lake and warehouse."),(0,n.yg)("p",null,"This platform uses technologies including, but not limited to:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("a",{parentName:"li",href:"http://flink.apache.org"},"Apache Flink")),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("a",{parentName:"li",href:"http://spark.apache.org"},"Apache Spark")),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("a",{parentName:"li",href:"http://hadoop.apache.org"},"Apache YARN")),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("a",{parentName:"li",href:"https://spring.io/projects/spring-boot/"},"Spring Boot")),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("a",{parentName:"li",href:"http://www.mybatis.org"},"Mybatis")),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("a",{parentName:"li",href:"http://mp.baomidou.com"},"Mybatis-Plus")),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("a",{parentName:"li",href:"https://cn.vuejs.org/"},"Vue")),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("a",{parentName:"li",href:"https://vuepress.vuejs.org/"},"VuePress")),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("a",{parentName:"li",href:"https://antdv.com/"},"Ant Design of Vue")),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("a",{parentName:"li",href:"https://pro.antdv"},"ANTD PRO VUE")),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("a",{parentName:"li",href:"https://xtermjs.org/"},"xterm.js")),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("a",{parentName:"li",href:"https://microsoft.github.io/monaco-editor/"},"Monaco Editor"))),(0,n.yg)("p",null,"Thanks for the support and inspiration given by the above excellent open source projects and many other excellent open source projects not mentioned here!"))}u.isMDXComponent=!0},60941:(e,a,t)=>{t.d(a,{A:()=>r});const r=t.p+"assets/images/streampark_archite-ff9eba80347b8b3c47d241007386f7bc.png"}}]);